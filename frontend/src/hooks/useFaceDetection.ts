import { useState, useEffect, useRef, useCallback } from "react";
import * as H from "@vladmandic/human";
import { toast } from "sonner";

// 1. ì¸í„°í˜ì´ìŠ¤ ì •ì˜ ì œê±° ë° íƒ€ì… ë³„ì¹­ ì‚¬ìš©
// type BoxData extends faceapi.Box {}
// type DetectionData extends faceapi.FaceDetection {}
// type LandmarksData extends faceapi.FaceLandmarks68 {}

// Human ë¼ì´ë¸ŒëŸ¬ë¦¬ íƒ€ì… ì •ì˜
interface FaceResult {
  mesh?: number[][];
  iris?: Array<{ center: number[] }>;
  emotion?: Array<{ emotion: string; score: number }>;
  boxScore?: number;
}

export interface FaceAnalysisResult {
  isDrowsy: boolean;
  isAttentive: boolean;
  emotion: string;
  ear: number;
  mar: number; // Mouth Aspect Ratio
  isYawning: boolean; // í•˜í’ˆ ì—¬ë¶€
  gazeDirection: 'left' | 'right' | 'up' | 'down' | 'center' | 'unknown';
  headPose: {
    yaw: number;    // ì¢Œìš° íšŒì „
    pitch: number;  // ìƒí•˜ íšŒì „
    roll: number;   // ê¸°ìš¸ê¸°
  };
  blinkRate: number;
  attentionScore: number; // 0-100 ì ìˆ˜
  fatigueLevel: 'low' | 'medium' | 'high';
  confidence: number;
}

interface UseFaceDetectionProps {
  videoRef: React.RefObject<HTMLVideoElement>;
  canvasRef: React.RefObject<HTMLCanvasElement>;
  onFaceDetected: (result?: FaceAnalysisResult) => void;
  onFaceNotDetected: () => void;
  showPreview: boolean;
}

// Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
const humanConfig: Partial<H.Config> = {
  debug: false,
  backend: 'webgl',
  modelBasePath: 'https://vladmandic.github.io/human-models/models/',
  filter: { enabled: true, equalization: false, flip: false },
  face: { 
    enabled: true, 
    detector: { rotation: false, return: true, mask: false }, 
    mesh: { enabled: true }, 
    attention: { enabled: true }, 
    iris: { enabled: true }, 
    description: { enabled: true }, 
    emotion: { enabled: true }, 
    antispoof: { enabled: false }, // ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ë¹„í™œì„±í™”
    liveness: { enabled: false }   // ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ë¹„í™œì„±í™”
  },
  body: { enabled: false },
  hand: { enabled: false },
  object: { enabled: false },
  segmentation: { enabled: false },
  gesture: { enabled: false }, // ë¶ˆí•„ìš”í•œ ê¸°ëŠ¥ ë¹„í™œì„±í™”
};

// EAR (Eye Aspect Ratio) ê³„ì‚° í•¨ìˆ˜ - Human ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ iris ë°ì´í„° ì‚¬ìš©
const computeEAR = (eyePoints: number[][]): number => {
  if (!eyePoints || eyePoints.length < 6) return 0.3;
  
  // ëˆˆì˜ ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚°
  const verticalDist1 = Math.sqrt(
    Math.pow(eyePoints[1][0] - eyePoints[5][0], 2) + 
    Math.pow(eyePoints[1][1] - eyePoints[5][1], 2)
  );
  const verticalDist2 = Math.sqrt(
    Math.pow(eyePoints[2][0] - eyePoints[4][0], 2) + 
    Math.pow(eyePoints[2][1] - eyePoints[4][1], 2)
  );
  
  // ëˆˆì˜ ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
  const horizontalDist = Math.sqrt(
    Math.pow(eyePoints[0][0] - eyePoints[3][0], 2) + 
    Math.pow(eyePoints[0][1] - eyePoints[3][1], 2)
  );
  
  if (horizontalDist === 0) return 0.3;
  
  return (verticalDist1 + verticalDist2) / (2.0 * horizontalDist);
};

// MAR (Mouth Aspect Ratio) ê³„ì‚° í•¨ìˆ˜
const computeMAR = (mouthPoints: number[][]): number => {
  if (!mouthPoints || mouthPoints.length < 8) return 0.0;
  
  // ì…ì˜ ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚°
  const verticalDist1 = Math.sqrt(
    Math.pow(mouthPoints[2][0] - mouthPoints[6][0], 2) + 
    Math.pow(mouthPoints[2][1] - mouthPoints[6][1], 2)
  );
  const verticalDist2 = Math.sqrt(
    Math.pow(mouthPoints[3][0] - mouthPoints[5][0], 2) + 
    Math.pow(mouthPoints[3][1] - mouthPoints[5][1], 2)
  );
  
  // ì…ì˜ ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
  const horizontalDist = Math.sqrt(
    Math.pow(mouthPoints[0][0] - mouthPoints[4][0], 2) + 
    Math.pow(mouthPoints[0][1] - mouthPoints[4][1], 2)
  );
  
  if (horizontalDist === 0) return 0.0;
  
  return (verticalDist1 + verticalDist2) / (2.0 * horizontalDist);
};

// ë¨¸ë¦¬ ìì„¸ ì¶”ì • (ê°œì„ ëœ ë²„ì „)
const estimateHeadPose = (face: FaceResult): { yaw: number; pitch: number; roll: number } => {
  if (!face.mesh || face.mesh.length < 468) {
    return { yaw: 0, pitch: 0, roll: 0 };
  }

  // ë” ì •í™•í•œ ì–¼êµ´ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ë“¤ ì‚¬ìš©
  const noseTip = face.mesh[1];     // ì½”ë
  const noseBase = face.mesh[168];  // ì½” ê¸°ì €
  const leftEyeOuter = face.mesh[33];   // ì™¼ìª½ ëˆˆ ì™¸ì¸¡
  const rightEyeOuter = face.mesh[263]; // ì˜¤ë¥¸ìª½ ëˆˆ ì™¸ì¸¡
  const leftEyeInner = face.mesh[133];  // ì™¼ìª½ ëˆˆ ë‚´ì¸¡
  const rightEyeInner = face.mesh[362]; // ì˜¤ë¥¸ìª½ ëˆˆ ë‚´ì¸¡
  const chin = face.mesh[175];      // í„± ë
  const forehead = face.mesh[10];   // ì´ë§ˆ

  // ì•ˆì „ì„± ê²€ì‚¬
  if (!noseTip || !noseBase || !leftEyeOuter || !rightEyeOuter || 
      !leftEyeInner || !rightEyeInner || !chin || !forehead) {
    return { yaw: 0, pitch: 0, roll: 0 };
  }

  // ëˆˆ ì¤‘ì‹¬ì  ê³„ì‚°
  const eyeCenter = [
    (leftEyeOuter[0] + rightEyeOuter[0] + leftEyeInner[0] + rightEyeInner[0]) / 4,
    (leftEyeOuter[1] + rightEyeOuter[1] + leftEyeInner[1] + rightEyeInner[1]) / 4
  ];

  // Yaw (ì¢Œìš° íšŒì „) - ì½”ì™€ ëˆˆ ì¤‘ì‹¬ì˜ ìˆ˜í‰ ì˜¤í”„ì…‹ ê¸°ë°˜
  const faceWidth = Math.abs(rightEyeOuter[0] - leftEyeOuter[0]);
  const noseOffsetX = noseTip[0] - eyeCenter[0];
  let yaw = (noseOffsetX / faceWidth) * 60; // ì •ê·œí™”ëœ ê°ë„
  yaw = Math.max(-45, Math.min(45, yaw)); // -45ë„ ~ +45ë„ë¡œ ì œí•œ

  // Pitch (ìƒí•˜ íšŒì „) - ì´ë§ˆ-ëˆˆ-í„±ì˜ ìˆ˜ì§ ê´€ê³„ ê¸°ë°˜
  const faceHeight = Math.abs(forehead[1] - chin[1]);
  const eyeToForeheadDist = Math.abs(forehead[1] - eyeCenter[1]);
  const eyeToChinDist = Math.abs(chin[1] - eyeCenter[1]);
  
  // ì •ìƒì ì¸ ë¹„ìœ¨ì—ì„œì˜ í¸ì°¨ ê³„ì‚°
  const normalRatio = 0.4; // ì •ìƒì ìœ¼ë¡œ ëˆˆì´ ì–¼êµ´ ë†’ì´ì˜ 40% ìœ„ì¹˜
  const currentRatio = eyeToForeheadDist / faceHeight;
  let pitch = (currentRatio - normalRatio) * 150; // ì •ê·œí™”ëœ ê°ë„
  pitch = Math.max(-30, Math.min(30, pitch)); // -30ë„ ~ +30ë„ë¡œ ì œí•œ

  // Roll (ê¸°ìš¸ê¸°) - ë‘ ëˆˆì˜ ê¸°ìš¸ê¸°
  const eyeVector = [rightEyeOuter[0] - leftEyeOuter[0], rightEyeOuter[1] - leftEyeOuter[1]];
  let roll = Math.atan2(eyeVector[1], eyeVector[0]) * (180 / Math.PI);
  roll = Math.max(-30, Math.min(30, roll)); // -30ë„ ~ +30ë„ë¡œ ì œí•œ

  return { yaw, pitch, roll };
};

// ì‹œì„  ë°©í–¥ ì¶”ì • (ê°œì„ ëœ ë²„ì „)
const estimateGazeDirection = (face: FaceResult): 'left' | 'right' | 'up' | 'down' | 'center' | 'unknown' => {
  // iris ë°ì´í„° ê²€ì¦
  if (!face.iris || face.iris.length < 2) {
    // console.log("ğŸ‘ï¸ iris ë°ì´í„° ì—†ìŒ:", { hasIris: !!face.iris, length: face.iris?.length });
    return 'unknown';
  }

  const leftIris = face.iris[0];
  const rightIris = face.iris[1];

  if (!leftIris || !rightIris || !leftIris.center || !rightIris.center) {
    console.log("ğŸ‘ï¸ iris center ë°ì´í„° ë¶€ì¡±:", { 
      leftIris: !!leftIris, 
      rightIris: !!rightIris,
      leftCenter: !!leftIris?.center,
      rightCenter: !!rightIris?.center
    });
    return 'unknown';
  }

  // Human ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ meshë¥¼ ì‚¬ìš©í•˜ì—¬ ëˆˆ ì˜ì—­ ê³„ì‚°
  if (!face.mesh || face.mesh.length < 468) {
    console.log("ğŸ‘ï¸ mesh ë°ì´í„° ë¶€ì¡±:", { hasMesh: !!face.mesh, length: face.mesh?.length });
    return 'unknown';
  }
  
  // ë” ì •í™•í•œ ëˆˆ ëœë“œë§ˆí¬ ì‚¬ìš©
  const leftEyeInner = face.mesh[133];   // ì™¼ìª½ ëˆˆ ë‚´ì¸¡
  const leftEyeOuter = face.mesh[33];    // ì™¼ìª½ ëˆˆ ì™¸ì¸¡
  const rightEyeInner = face.mesh[362];  // ì˜¤ë¥¸ìª½ ëˆˆ ë‚´ì¸¡
  const rightEyeOuter = face.mesh[263];  // ì˜¤ë¥¸ìª½ ëˆˆ ì™¸ì¸¡
  
  if (!leftEyeInner || !leftEyeOuter || !rightEyeInner || !rightEyeOuter) {
    console.log("ğŸ‘ï¸ ëˆˆ ëœë“œë§ˆí¬ ë°ì´í„° ë¶€ì¡±");
    return 'unknown';
  }
  
  // ì™¼ìª½ ëˆˆê³¼ ì˜¤ë¥¸ìª½ ëˆˆì˜ ì¤‘ì‹¬ì  ê³„ì‚°
  const leftEyeCenter = [(leftEyeInner[0] + leftEyeOuter[0]) / 2, (leftEyeInner[1] + leftEyeOuter[1]) / 2];
  const rightEyeCenter = [(rightEyeInner[0] + rightEyeOuter[0]) / 2, (rightEyeInner[1] + rightEyeOuter[1]) / 2];
  
  // ê° ëˆˆì—ì„œ í™ì±„ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°
  const leftGazeOffsetX = leftIris.center[0] - leftEyeCenter[0];
  const leftGazeOffsetY = leftIris.center[1] - leftEyeCenter[1];
  const rightGazeOffsetX = rightIris.center[0] - rightEyeCenter[0];
  const rightGazeOffsetY = rightIris.center[1] - rightEyeCenter[1];
  
  // ë‘ ëˆˆì˜ í‰ê·  ì‹œì„  ë°©í–¥ ê³„ì‚°
  const avgGazeX = (leftGazeOffsetX + rightGazeOffsetX) / 2;
  const avgGazeY = (leftGazeOffsetY + rightGazeOffsetY) / 2;
  
  // ëˆˆ í¬ê¸° ê¸°ë°˜ ì ì‘í˜• ì„ê³„ê°’ ê³„ì‚°
  const eyeWidth = Math.abs(leftEyeOuter[0] - leftEyeInner[0]);
  const thresholdX = eyeWidth * 0.15; // ëˆˆ ë„ˆë¹„ì˜ 15%
  const thresholdY = eyeWidth * 0.1;  // ëˆˆ ë„ˆë¹„ì˜ 10%
  
  console.log("ğŸ‘ï¸ ì‹œì„  ë¶„ì„:", {
    leftGazeOffset: [leftGazeOffsetX.toFixed(2), leftGazeOffsetY.toFixed(2)],
    rightGazeOffset: [rightGazeOffsetX.toFixed(2), rightGazeOffsetY.toFixed(2)],
    avgGaze: [avgGazeX.toFixed(2), avgGazeY.toFixed(2)],
    thresholds: [thresholdX.toFixed(2), thresholdY.toFixed(2)],
    eyeWidth: eyeWidth.toFixed(2)
  });
  
  // ì‹œì„  ë°©í–¥ ê²°ì •
  if (Math.abs(avgGazeX) < thresholdX && Math.abs(avgGazeY) < thresholdY) return 'center';
  if (avgGazeX > thresholdX) return 'right';
  if (avgGazeX < -thresholdX) return 'left';
  if (avgGazeY > thresholdY) return 'down';
  if (avgGazeY < -thresholdY) return 'up';
  
  return 'center';
};

// ì£¼ì˜ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚°
const calculateAttentionScore = (
  ear: number, 
  mar: number, 
  headPose: { yaw: number; pitch: number; roll: number },
  gaze: string,
  blinkRate: number,
  gazeStability: number // ì‹œì„  ì•ˆì •ì„± ì ìˆ˜ (0-100)
): number => {
  let score = 100;

  // ëˆˆ ê°ê¹€ ì •ë„ (-40ì )
  if (ear < 0.15) score -= 40;
  else if (ear < 0.20) score -= 20;
  else if (ear < 0.25) score -= 10;

  // ì… ë²Œë¦¼ ì •ë„ (-20ì )
  if (mar > 0.5) score -= 20;
  else if (mar > 0.3) score -= 10;

  // ë¨¸ë¦¬ ìì„¸ (-30ì )
  const headAngle = Math.abs(headPose.yaw) + Math.abs(headPose.pitch);
  if (headAngle > 30) score -= 30;
  else if (headAngle > 20) score -= 15;
  else if (headAngle > 10) score -= 5;

  // ì‹œì„  ì•ˆì •ì„± (-20ì ) - ì‹œì„ ì´ ì–¼ë§ˆë‚˜ ì¼ì •í•œ ê³³ì— ë¨¸ë¬¼ëŸ¬ ìˆëŠ”ì§€
  const gazeStabilityPenalty = Math.round((100 - gazeStability) * 0.2); // 0-20ì  ì°¨ê°
  score -= gazeStabilityPenalty;

  // ê¹œë¹¡ì„ ë¹ˆë„ (-15ì ) - 10ì´ˆ ë‹¨ìœ„ ì¸¡ì •ì— ë§ê²Œ ì¡°ì •
  if (blinkRate < 6) score -= 15;      // 10ì´ˆì— 1íšŒ ë¯¸ë§Œ (ë¶„ë‹¹ 6íšŒ ë¯¸ë§Œ) - ë§¤ìš° ì¡¸ë¦¼
  else if (blinkRate < 12) score -= 10; // 10ì´ˆì— 2íšŒ ë¯¸ë§Œ (ë¶„ë‹¹ 12íšŒ ë¯¸ë§Œ) - ì¡¸ë¦¼
  else if (blinkRate > 36) score -= 10; // 10ì´ˆì— 6íšŒ ì´ˆê³¼ (ë¶„ë‹¹ 36íšŒ ì´ˆê³¼) - ê³¼ë„í•œ ê¹œë¹¡ì„

  return Math.max(0, Math.min(100, score));
};

// í”¼ë¡œë„ ë ˆë²¨ í‰ê°€
const assessFatigueLevel = (attentionScore: number, ear: number, consecutiveDrowsyFrames: number): 'low' | 'medium' | 'high' => {
  if (attentionScore < 40 || ear < 0.15 || consecutiveDrowsyFrames > 20) return 'high';   // 3ì´ˆ ì§€ì†
  if (attentionScore < 70 || ear < 0.20 || consecutiveDrowsyFrames > 10) return 'medium'; // 1.5ì´ˆ ì§€ì†
  return 'low';
};

export const useFaceDetection = ({
  videoRef,
  canvasRef,
  onFaceDetected,
  onFaceNotDetected,
  showPreview,
}: UseFaceDetectionProps) => {
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isDetecting, setIsDetecting] = useState(false);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [lastDetectionTime, setLastDetectionTime] = useState(Date.now());
  const [modelLoadingError, setModelLoadingError] = useState<string | null>(null);
  
  const [blinkHistory, setBlinkHistory] = useState<number[]>([]);
  const [consecutiveDrowsyFrames, setConsecutiveDrowsyFrames] = useState(0);
  const [earHistory, setEarHistory] = useState<number[]>([]);
  const [attentionHistory, setAttentionHistory] = useState<number[]>([]);
  
  // ê¹œë¹¡ì„ ê°ì§€ë¥¼ ìœ„í•œ ìƒíƒœ ì¶”ê°€
  const [blinkTimestamps, setBlinkTimestamps] = useState<number[]>([]);
  const [isEyeClosed, setIsEyeClosed] = useState(false);
  const [lastBlinkTime, setLastBlinkTime] = useState(0);
  
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const frameCountRef = useRef(0);
  const animationFrameRef = useRef<number | null>(null);
  
  const lastDetectionsRef = useRef<H.Result | null>(null);
  const isDetectingRef = useRef(false);
  const humanRef = useRef<H.Human | null>(null);

  // ê¹œë¹¡ì„ ê´€ë ¨ refë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
  const blinkTimestampsRef = useRef<number[]>([]);
  const isEyeClosedRef = useRef(false);
  const lastBlinkTimeRef = useRef(0);

  // ìƒíƒœ íˆìŠ¤í† ë¦¬ë„ refë¡œ ê´€ë¦¬í•˜ì—¬ ì„±ëŠ¥ ê°œì„ 
  const consecutiveDrowsyFramesRef = useRef(0);
  const earHistoryRef = useRef<number[]>([]);
  const attentionHistoryRef = useRef<number[]>([]);
  
  // ì‹œì„  ì•ˆì •ì„± ì¶”ì ì„ ìœ„í•œ íˆìŠ¤í† ë¦¬
  const gazeHistoryRef = useRef<string[]>([]);
  const GAZE_HISTORY_LENGTH = 30; // ìµœê·¼ 30í”„ë ˆì„ì˜ ì‹œì„  ë°©í–¥ ì¶”ì 
  
  // ì¡¸ìŒ ê°ì§€ë¥¼ ìœ„í•œ ê³ ê¸‰ ìƒíƒœ ì¶”ì 
  const eyeClosedDurationRef = useRef(0); // ëˆˆì´ ê°ê¸´ ì§€ì† ì‹œê°„
  const slowBlinkCountRef = useRef(0); // ëŠë¦° ê¹œë¹¡ì„ íšŸìˆ˜
  const lastEyeStateRef = useRef<'open' | 'closed'>('open'); // ì´ì „ ëˆˆ ìƒíƒœ
  const eyeStateChangeTimeRef = useRef(Date.now()); // ë§ˆì§€ë§‰ ëˆˆ ìƒíƒœ ë³€í™” ì‹œê°„
  const headDropCountRef = useRef(0); // ë¨¸ë¦¬ê°€ ë–¨ì–´ì§€ëŠ” íšŸìˆ˜
  const lastHeadPitchRef = useRef(0); // ì´ì „ ë¨¸ë¦¬ ê°ë„
  
  // ì´ˆê¸° í”„ë ˆì„ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì¹´ìš´í„°
  const stableFrameCountRef = useRef(0);
  const STABLE_FRAME_THRESHOLD = 10; // 10í”„ë ˆì„ í›„ë¶€í„° ì•ˆì •ì ì¸ ê²°ê³¼ ì‚¬ìš©

  // ì‹œì„  ì•ˆì •ì„± ê³„ì‚° í•¨ìˆ˜
  const calculateGazeStability = useCallback((currentGaze: string): number => {
    // í˜„ì¬ ì‹œì„ ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    gazeHistoryRef.current.push(currentGaze);
    
    // íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
    if (gazeHistoryRef.current.length > GAZE_HISTORY_LENGTH) {
      gazeHistoryRef.current = gazeHistoryRef.current.slice(-GAZE_HISTORY_LENGTH);
    }
    
    // ìµœì†Œ 10ê°œì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ê³„ì‚°
    if (gazeHistoryRef.current.length < 10) {
      return 70; // ì´ˆê¸°ê°’ì€ ì¤‘ê°„ ì •ë„
    }
    
    // ê°€ì¥ ë¹ˆë²ˆí•œ ì‹œì„  ë°©í–¥ ì°¾ê¸°
    const gazeCounts: { [key: string]: number } = {};
    gazeHistoryRef.current.forEach(gaze => {
      gazeCounts[gaze] = (gazeCounts[gaze] || 0) + 1;
    });
    
    const mostFrequentGaze = Object.keys(gazeCounts).reduce((a, b) => 
      gazeCounts[a] > gazeCounts[b] ? a : b
    );
    
    // ê°€ì¥ ë¹ˆë²ˆí•œ ë°©í–¥ì˜ ë¹„ìœ¨ ê³„ì‚°
    const mostFrequentCount = gazeCounts[mostFrequentGaze];
    const stabilityRatio = mostFrequentCount / gazeHistoryRef.current.length;
    
    // ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° (0-100)
    // 80% ì´ìƒ ì¼ì •í•˜ë©´ ë§Œì , 50% ë¯¸ë§Œì´ë©´ 0ì 
    let stabilityScore = 0;
    if (stabilityRatio >= 0.8) {
      stabilityScore = 100;
    } else if (stabilityRatio >= 0.7) {
      stabilityScore = 85;
    } else if (stabilityRatio >= 0.6) {
      stabilityScore = 70;
    } else if (stabilityRatio >= 0.5) {
      stabilityScore = 50;
    } else {
      stabilityScore = Math.round(stabilityRatio * 100);
    }
    
    // console.log("ğŸ‘ï¸ ì‹œì„  ì•ˆì •ì„± ë¶„ì„:", {
    //   currentGaze,
    //   mostFrequentGaze,
    //   stabilityRatio: stabilityRatio.toFixed(2),
    //   stabilityScore,
    //   historyLength: gazeHistoryRef.current.length
    // });
    
    return stabilityScore;
  }, [GAZE_HISTORY_LENGTH]);

  // ê³ ê¸‰ ì¡¸ìŒ ê°ì§€ í•¨ìˆ˜
  const detectAdvancedDrowsiness = useCallback((
    ear: number, 
    mar: number, 
    headPose: { yaw: number; pitch: number; roll: number },
    blinkRate: number
  ): boolean => {
    const currentTime = Date.now();
    const DROWSY_EAR_THRESHOLD = 0.18; // ì¡¸ìŒ ì„ê³„ê°’ (ë” ì—„ê²©)
    const SLOW_BLINK_DURATION = 500; // ëŠë¦° ê¹œë¹¡ì„ ê¸°ì¤€ (0.5ì´ˆ ì´ìƒ)
    const HEAD_DROP_THRESHOLD = 15; // ë¨¸ë¦¬ ë–¨ì–´ì§ ì„ê³„ê°’
    const SUSTAINED_CLOSED_THRESHOLD = 2000; // ì§€ì†ì ìœ¼ë¡œ ëˆˆ ê°ìŒ ê¸°ì¤€ (2ì´ˆ)
    
    // 1. ëˆˆ ìƒíƒœ ë³€í™” ì¶”ì 
    const currentEyeState = ear < DROWSY_EAR_THRESHOLD ? 'closed' : 'open';
    
    if (currentEyeState !== lastEyeStateRef.current) {
      const stateDuration = currentTime - eyeStateChangeTimeRef.current;
      
      // ëŠë¦° ê¹œë¹¡ì„ ê°ì§€ (ëˆˆì´ ì˜¤ë˜ ê°ê²¨ìˆì—ˆë˜ ê²½ìš°)
      if (lastEyeStateRef.current === 'closed' && stateDuration > SLOW_BLINK_DURATION) {
        slowBlinkCountRef.current += 1;
        console.log("ğŸ˜´ ëŠë¦° ê¹œë¹¡ì„ ê°ì§€:", { duration: stateDuration, count: slowBlinkCountRef.current });
      }
      
      lastEyeStateRef.current = currentEyeState;
      eyeStateChangeTimeRef.current = currentTime;
      
      // ëˆˆì´ ë‹¤ì‹œ ëœ¨ë©´ ì§€ì†ì‹œê°„ ë¦¬ì…‹
      if (currentEyeState === 'open') {
        eyeClosedDurationRef.current = 0;
      }
    }
    
    // 2. ì§€ì†ì ì¸ ëˆˆ ê°ìŒ ì¶”ì 
    if (currentEyeState === 'closed') {
      eyeClosedDurationRef.current = currentTime - eyeStateChangeTimeRef.current;
    }
    
    // 3. ë¨¸ë¦¬ ë–¨ì–´ì§ ê°ì§€
    const headPitchChange = headPose.pitch - lastHeadPitchRef.current;
    if (headPitchChange > 5 && headPose.pitch > HEAD_DROP_THRESHOLD) {
      headDropCountRef.current += 1;
      console.log("ğŸ“‰ ë¨¸ë¦¬ ë–¨ì–´ì§ ê°ì§€:", { 
        pitchChange: headPitchChange.toFixed(1), 
        currentPitch: headPose.pitch.toFixed(1),
        count: headDropCountRef.current 
      });
    }
    lastHeadPitchRef.current = headPose.pitch;
    
    // 4. ì… ë²Œë¦¼ (í•˜í’ˆ) ê°ì§€
    const isYawning = mar > 0.6; // í•˜í’ˆ ì„ê³„ê°’
    
    // 5. ì¢…í•©ì ì¸ ì¡¸ìŒ íŒì •
    let drowsinessScore = 0;
    
    // ì§€ì†ì ìœ¼ë¡œ ëˆˆ ê°ìŒ (ê°€ì¥ ê°•ë ¥í•œ ì§€í‘œ)
    if (eyeClosedDurationRef.current > SUSTAINED_CLOSED_THRESHOLD) {
      drowsinessScore += 40;
      console.log("ğŸ’¤ ì§€ì†ì  ëˆˆ ê°ìŒ:", { duration: eyeClosedDurationRef.current });
    }
    
    // ëŠë¦° ê¹œë¹¡ì„ íŒ¨í„´ (ìµœê·¼ 20ì´ˆê°„ 3íšŒ ì´ìƒ)
    if (slowBlinkCountRef.current >= 3) {
      drowsinessScore += 25;
      console.log("ğŸŒ ëŠë¦° ê¹œë¹¡ì„ íŒ¨í„´:", { count: slowBlinkCountRef.current });
    }
    
    // ë¨¸ë¦¬ ë–¨ì–´ì§ (ìµœê·¼ 30ì´ˆê°„ 2íšŒ ì´ìƒ)
    if (headDropCountRef.current >= 2) {
      drowsinessScore += 20;
      console.log("ğŸ“‰ ë°˜ë³µì  ë¨¸ë¦¬ ë–¨ì–´ì§:", { count: headDropCountRef.current });
    }
    
    // ë‚®ì€ ê¹œë¹¡ì„ ë¹ˆë„ (ì¡¸ë¦´ ë•Œ ê¹œë¹¡ì„ì´ ì¤„ì–´ë“¦)
    if (blinkRate < 8) {
      drowsinessScore += 15;
      // console.log("ğŸ‘ï¸ ë‚®ì€ ê¹œë¹¡ì„ ë¹ˆë„:", { rate: blinkRate });
    }
    
    // í•˜í’ˆ
    if (isYawning) {
      drowsinessScore += 10;
      console.log("ğŸ¥± í•˜í’ˆ ê°ì§€:", { mar: mar.toFixed(3) });
    }
    
    // 20ì´ˆë§ˆë‹¤ ì¹´ìš´í„° ë¦¬ì…‹ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
    if (currentTime % 20000 < 150) { // ê°ì§€ ì£¼ê¸°ê°€ 150msì´ë¯€ë¡œ
      slowBlinkCountRef.current = Math.max(0, slowBlinkCountRef.current - 1);
      headDropCountRef.current = Math.max(0, headDropCountRef.current - 1);
    }
    
    const isDrowsy = drowsinessScore >= 30; // 30ì  ì´ìƒì´ë©´ ì¡¸ìŒ
    
    if (isDrowsy) {
      console.log("ğŸ˜´ ê³ ê¸‰ ì¡¸ìŒ ê°ì§€!", {
        score: drowsinessScore,
        factors: {
          sustainedClosed: eyeClosedDurationRef.current > SUSTAINED_CLOSED_THRESHOLD,
          slowBlinks: slowBlinkCountRef.current >= 3,
          headDrops: headDropCountRef.current >= 2,
          lowBlinkRate: blinkRate < 8,
          yawning: isYawning
        }
      });
    }
    
    return isDrowsy;
  }, []);

  // ê¹œë¹¡ì„ ê°ì§€ í•¨ìˆ˜
  const detectBlink = useCallback((ear: number): number => {
    const currentTime = Date.now();
    const BLINK_THRESHOLD = 0.22; // ì„ê³„ê°’ì„ ì•½ê°„ ë‚®ì¶°ì„œ ë” ì •í™•í•œ ê°ì§€
    const MIN_BLINK_DURATION = 80;  // ìµœì†Œ ì§€ì†ì‹œê°„ì„ ì•½ê°„ ì¤„ì„
    const MAX_BLINK_DURATION = 600; // ìµœëŒ€ ì§€ì†ì‹œê°„ì„ ì•½ê°„ ëŠ˜ë¦¼
    
    // ëˆˆì´ ê°ê¸´ ìƒíƒœ ê°ì§€
    if (ear < BLINK_THRESHOLD && !isEyeClosedRef.current) {
      console.log("ğŸ‘ï¸ ëˆˆ ê°ê¹€ ê°ì§€:", { ear: ear.toFixed(3), time: currentTime });
      isEyeClosedRef.current = true;
      lastBlinkTimeRef.current = currentTime;
      setIsEyeClosed(true);
      setLastBlinkTime(currentTime);
    }
    // ëˆˆì´ ë‹¤ì‹œ ëœ¬ ìƒíƒœ ê°ì§€ (ê¹œë¹¡ì„ ì™„ë£Œ)
    else if (ear >= BLINK_THRESHOLD && isEyeClosedRef.current) {
      const blinkDuration = currentTime - lastBlinkTimeRef.current;
      console.log("ğŸ‘ï¸ ëˆˆ ëœ¸ ê°ì§€:", { 
        ear: ear.toFixed(3), 
        duration: blinkDuration,
        isValid: blinkDuration >= MIN_BLINK_DURATION && blinkDuration <= MAX_BLINK_DURATION
      });
      
      // ìœ íš¨í•œ ê¹œë¹¡ì„ì¸ì§€ í™•ì¸
      if (blinkDuration >= MIN_BLINK_DURATION && blinkDuration <= MAX_BLINK_DURATION) {
        console.log("âœ… ìœ íš¨í•œ ê¹œë¹¡ì„ ê°ì§€ë¨!", { duration: blinkDuration });
        const newTimestamps = [...blinkTimestampsRef.current, currentTime];
        const filtered = newTimestamps.filter(timestamp => currentTime - timestamp <= 10000); // 10ì´ˆë¡œ ë³€ê²½
        blinkTimestampsRef.current = filtered;
        setBlinkTimestamps(filtered);
      }
      
      isEyeClosedRef.current = false;
      setIsEyeClosed(false);
    }
    
    // í˜„ì¬ 10ì´ˆê°„ ê¹œë¹¡ì„ íšŸìˆ˜ ê³„ì‚° í›„ ë¶„ë‹¹ í™˜ì‚°
    const MEASUREMENT_WINDOW = 10000; // 10ì´ˆ
    const recentBlinks = blinkTimestampsRef.current.filter(timestamp => currentTime - timestamp <= MEASUREMENT_WINDOW);
    
    // 10ì´ˆê°„ ê¹œë¹¡ì„ì„ ë¶„ë‹¹ ê¹œë¹¡ì„ìœ¼ë¡œ í™˜ì‚° (10ì´ˆ * 6 = 1ë¶„)
    const blinksPer10Seconds = recentBlinks.length;
    const blinksPerMinute = Math.round(blinksPer10Seconds * 6);
    
    return blinksPerMinute;
  }, []);

  // Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ˆê¸°í™”
  useEffect(() => {
    const initializeHuman = async () => {
      try {
        console.log("ğŸ§  Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ˆê¸°í™” ì‹œì‘...");
        const human = new H.Human(humanConfig);
        humanRef.current = human;
        
        await human.load();
        console.log("ğŸ¯ Human ëª¨ë¸ ë¡œë”© ì™„ë£Œ!");
        
        await human.warmup();
        console.log("ğŸš€ Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤€ë¹„ ì™„ë£Œ!");
        
        setIsModelLoaded(true);
      } catch (error) {
        console.error("âŒ Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨:", error);
        setModelLoadingError("AI ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
        toast.error("AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }
    };

    initializeHuman();

    return () => {
      if (detectionIntervalRef.current) clearInterval(detectionIntervalRef.current);
      if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    };
  }, []);

  // ì¹´ë©”ë¼ ì¤€ë¹„ ìƒíƒœ ì²´í¬
  useEffect(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!video || !canvas) return;

    const updateCanvasGeometry = () => {
      console.log("ğŸ¨ ìº”ë²„ìŠ¤ ì§€ì˜¤ë©”íŠ¸ë¦¬ ì—…ë°ì´íŠ¸:", {
        videoWidth: video.videoWidth,
        videoHeight: video.videoHeight,
        clientWidth: video.clientWidth,
        clientHeight: video.clientHeight,
        readyState: video.readyState
      });

      if (!video.videoWidth || !video.videoHeight || video.clientWidth === 0 || video.clientHeight === 0) {
        setIsCameraReady(false);
        return;
      }

      const devicePixelRatio = window.devicePixelRatio || 1;
      const videoClientWidth = video.clientWidth;
      const videoClientHeight = video.clientHeight;
      
      canvas.style.width = `${videoClientWidth}px`;
      canvas.style.height = `${videoClientHeight}px`;
      canvas.style.position = 'absolute';
      canvas.style.top = '0';
      canvas.style.left = '0';

      canvas.width = Math.round(videoClientWidth * devicePixelRatio);
      canvas.height = Math.round(videoClientHeight * devicePixelRatio);

      const ctx = canvas.getContext('2d');
      if (ctx) {
        ctx.setTransform(devicePixelRatio, 0, 0, devicePixelRatio, 0, 0);
      }
      
      console.log("âœ… ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ");
      setIsCameraReady(true);
    };

    const observer = new ResizeObserver(updateCanvasGeometry);
    observer.observe(video);
    video.addEventListener('loadedmetadata', updateCanvasGeometry);
    video.addEventListener('play', updateCanvasGeometry);
    video.addEventListener('resize', updateCanvasGeometry);
    video.addEventListener('loadeddata', updateCanvasGeometry);

    if (video.videoWidth && video.videoHeight && video.clientWidth && video.clientHeight) {
      updateCanvasGeometry();
    }

    return () => {
      observer.unobserve(video);
      observer.disconnect();
      video.removeEventListener('loadedmetadata', updateCanvasGeometry);
      video.removeEventListener('play', updateCanvasGeometry);
      video.removeEventListener('resize', updateCanvasGeometry);
      video.removeEventListener('loadeddata', updateCanvasGeometry);
      setIsCameraReady(false);
    };
  }, [videoRef, canvasRef]);

  const memoizedStopDetection = useCallback(() => {
    console.log("ğŸ›‘ ì–¼êµ´ ì¸ì‹ ì¤‘ì§€");
    setIsDetecting(false);
    isDetectingRef.current = false;
    if (detectionIntervalRef.current) clearInterval(detectionIntervalRef.current);
    detectionIntervalRef.current = null;
    if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    animationFrameRef.current = null;
    
    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      if (ctx) {
        const canvas = canvasRef.current;
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }
    }
    
    lastDetectionsRef.current = null;
    frameCountRef.current = 0;
    setConsecutiveDrowsyFrames(0);
    setEarHistory([]);
    setAttentionHistory([]);
    setBlinkTimestamps([]);
    setIsEyeClosed(false);
    setLastBlinkTime(0);
    
    // ref ì´ˆê¸°í™” ì¶”ê°€
    blinkTimestampsRef.current = [];
    isEyeClosedRef.current = false;
    lastBlinkTimeRef.current = 0;
    consecutiveDrowsyFramesRef.current = 0;
    earHistoryRef.current = [];
    attentionHistoryRef.current = [];
    gazeHistoryRef.current = [];
    stableFrameCountRef.current = 0;
    
    // ê³ ê¸‰ ì¡¸ìŒ ê°ì§€ ìƒíƒœ ì´ˆê¸°í™”
    eyeClosedDurationRef.current = 0;
    slowBlinkCountRef.current = 0;
    lastEyeStateRef.current = 'open';
    eyeStateChangeTimeRef.current = Date.now();
    headDropCountRef.current = 0;
    lastHeadPitchRef.current = 0;
  }, [canvasRef]);

  const drawDetections = useCallback((
    canvas: HTMLCanvasElement,
    result: H.Result | null
  ) => {
    const ctx = canvas.getContext('2d');
    if (!ctx || !result) return;

    const video = videoRef.current;
    if (!video) return;

    const devicePixelRatio = window.devicePixelRatio || 1;
    const cssDrawingWidth = video.clientWidth;
    const cssDrawingHeight = video.clientHeight;

    // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
    canvas.width = canvas.offsetWidth * devicePixelRatio;
    canvas.height = canvas.offsetHeight * devicePixelRatio;
 
    // ìº”ë²„ìŠ¤ë¥¼ ì‹¤ì œ í¬ê¸°ë¡œ í™•ëŒ€ (scale() ì‚¬ìš©)
    ctx.scale(devicePixelRatio, devicePixelRatio);

    // ìº”ë²„ìŠ¤ í´ë¦¬ì–´
    ctx.clearRect(0, 0, cssDrawingWidth, cssDrawingHeight);

    if (result.face && result.face.length > 0) {
      // Face ID ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ ê·¸ë¦¬ê¸°
      result.face.forEach((face) => {
        if (face.box && face.box.length >= 4) {
          // Human ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ box í˜•ì‹: [x, y, width, height]
          const [boxX, boxY, boxWidth, boxHeight] = face.box;
          
          // ë¹„ë””ì˜¤ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
          const video = videoRef.current;
          if (video && video.videoWidth && video.videoHeight) {
            const scaleX = cssDrawingWidth / video.videoWidth;
            const scaleY = cssDrawingHeight / video.videoHeight;
            
            const x = boxX * scaleX;
            const y = boxY * scaleY;
            const width = boxWidth * scaleX;
            const height = boxHeight * scaleY;
            
            // Face ID ìŠ¤íƒ€ì¼ ì½”ë„ˆ ê·¸ë¦¬ê¸°
            ctx.save();
            const cornerLineLength = 30;
            const cornerRadius = 8;
            ctx.strokeStyle = 'rgba(255, 255, 255, 0.9)';
            ctx.lineWidth = 4 / devicePixelRatio;
            ctx.lineCap = 'round';
            ctx.lineJoin = 'round';
            const rectX = x; 
            const rectY = y; 
            const rectWidth = width; 
            const rectHeight = height;
            
            const cornersForRect = [
              { x: rectX, y: rectY, type: 'topLeft' }, 
              { x: rectX + rectWidth, y: rectY, type: 'topRight' },
              { x: rectX, y: rectY + rectHeight, type: 'bottomLeft' }, 
              { x: rectX + rectWidth, y: rectY + rectHeight, type: 'bottomRight' }
            ];
            
            cornersForRect.forEach(corner => {
              ctx.beginPath();
              if (corner.type === 'topLeft') { 
                ctx.moveTo(corner.x + cornerLineLength, corner.y); 
                ctx.lineTo(corner.x + cornerRadius, corner.y); 
                ctx.quadraticCurveTo(corner.x, corner.y, corner.x, corner.y + cornerRadius); 
                ctx.lineTo(corner.x, corner.y + cornerLineLength); 
              }
              else if (corner.type === 'topRight') { 
                ctx.moveTo(corner.x - cornerLineLength, corner.y); 
                ctx.lineTo(corner.x - cornerRadius, corner.y); 
                ctx.quadraticCurveTo(corner.x, corner.y, corner.x, corner.y + cornerRadius); 
                ctx.lineTo(corner.x, corner.y + cornerLineLength); 
              }
              else if (corner.type === 'bottomLeft') { 
                ctx.moveTo(corner.x, corner.y - cornerLineLength); 
                ctx.lineTo(corner.x, corner.y - cornerRadius); 
                ctx.quadraticCurveTo(corner.x, corner.y, corner.x + cornerRadius, corner.y); 
                ctx.lineTo(corner.x + cornerLineLength, corner.y); 
              }
              else { 
                ctx.moveTo(corner.x, corner.y - cornerLineLength); 
                ctx.lineTo(corner.x, corner.y - cornerRadius); 
                ctx.quadraticCurveTo(corner.x, corner.y, corner.x - cornerRadius, corner.y); 
                ctx.lineTo(corner.x - cornerLineLength, corner.y); 
              }
              ctx.stroke();
            });
            ctx.restore();
          }
        }
      });

      // ì¶”ê°€ë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° (Human ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
      if (humanRef.current && showPreview) {
        // ì–¼êµ´ ë©”ì‹œ í¬ì¸íŠ¸ë“¤ì„ ê°€ë³ê²Œ ê·¸ë¦¬ê¸°
        result.face.forEach((face) => {
          if (face.mesh && face.mesh.length > 0) {
            const video = videoRef.current;
            if (video && video.videoWidth && video.videoHeight) {
              const scaleX = cssDrawingWidth / video.videoWidth;
              const scaleY = cssDrawingHeight / video.videoHeight;
              
              ctx.save();
              ctx.fillStyle = 'rgba(255, 255, 255, 0.3)';
              face.mesh.forEach((point, index) => {
                // ì£¼ìš” í¬ì¸íŠ¸ë“¤ë§Œ ê·¸ë¦¬ê¸° (ëˆˆ, ì½”, ì… ë“±)
                if (index % 8 === 0) { // 8ê°œ ì¤‘ 1ê°œë§Œ ê·¸ë¦¬ê¸°
                  const x = point[0] * scaleX;
                  const y = point[1] * scaleY;
                  ctx.beginPath();
                  ctx.arc(x, y, 1 / devicePixelRatio, 0, 2 * Math.PI);
                  ctx.fill();
                }
              });
              ctx.restore();
            }
          }
        });
      }
    } else {
      // ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì„ ë•Œ ê°€ì´ë“œ í‘œì‹œ
      const time = Date.now() / 1000;
      const pulseIntensity = 0.5 + 0.3 * Math.sin(time * 2);
      const guideWidth = Math.min(cssDrawingWidth * 0.6, 250);
      const guideHeight = guideWidth * 1.2;
      const guideX = (cssDrawingWidth - guideWidth) / 2;
      const guideY = (cssDrawingHeight - guideHeight) / 2;

      ctx.save();
      ctx.strokeStyle = `rgba(255, 255, 255, ${pulseIntensity * 0.6})`;
      ctx.lineWidth = 2 / devicePixelRatio;
      ctx.setLineDash([10 / devicePixelRatio, 5 / devicePixelRatio]);
      ctx.strokeRect(guideX, guideY, guideWidth, guideHeight);
      ctx.restore();

      ctx.save();
      ctx.fillStyle = `rgba(255, 255, 255, ${pulseIntensity * 0.8})`;
      ctx.font = `16px -apple-system, BlinkMacSystemFont, sans-serif`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      const textX = cssDrawingWidth / 2;
      const textY = guideY - 20;
      ctx.fillText('ì–¼êµ´ì„ í™”ë©´ì— ë§ì¶°ì£¼ì„¸ìš”', textX, textY);
      ctx.restore();
    }
  }, [videoRef]);

  const startDetection = useCallback(() => {
    console.log("ğŸš€ Human ê¸°ë°˜ ì–¼êµ´ ê°ì§€ ì‹œì‘");

    if (!isModelLoaded || !humanRef.current) {
      console.log("âŒ Human ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ");
      toast.error("AI ëª¨ë¸ ë¡œë”© í•„ìš”");
      return;
    }

    if (isDetectingRef.current) {
      console.log("âš ï¸ ì´ë¯¸ ê°ì§€ ì‹¤í–‰ ì¤‘");
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;

    if (!video || !canvas) {
      console.log("âŒ ë¹„ë””ì˜¤ ë˜ëŠ” ìº”ë²„ìŠ¤ ìš”ì†Œê°€ ì—†ìŒ");
      return;
    }

    if (video.readyState < 2 || !video.videoWidth || !video.videoHeight) {
      console.log("â³ ë¹„ë””ì˜¤ ì¤€ë¹„ ëŒ€ê¸° ì¤‘...");
      setTimeout(() => startDetection(), 500);
      return;
    }

    console.log("âœ… ëª¨ë“  ì¡°ê±´ ì¶©ì¡±, Human ê¸°ë°˜ ê°ì§€ ì‹œì‘");

    setIsDetecting(true);
    isDetectingRef.current = true;
    setLastDetectionTime(Date.now());
    frameCountRef.current = 0;

    // ê·¸ë¦¬ê¸° ë£¨í”„
    let lastAnimateTime = 0;
    const animate = (currentTime: number) => {
      if (!isDetectingRef.current) return;
      animationFrameRef.current = requestAnimationFrame(animate);
      if (currentTime - lastAnimateTime < 16) return; // ì•½ 60fps
      lastAnimateTime = currentTime;
      if (canvasRef.current && showPreview) {
        drawDetections(canvasRef.current, lastDetectionsRef.current);
      }
    };
    animationFrameRef.current = requestAnimationFrame(animate);

    // ê°ì§€ ë£¨í”„
    detectionIntervalRef.current = setInterval(async () => {
      const video = videoRef.current;
      if (video && isDetectingRef.current && video.readyState >= video.HAVE_ENOUGH_DATA && humanRef.current) {
        frameCountRef.current++;
        try {
          const result = await humanRef.current.detect(video);
          lastDetectionsRef.current = result;

          if (result.face && result.face.length > 0) {
            setLastDetectionTime(Date.now());
            const face = result.face[0];
            
            // ì´ˆê¸° í”„ë ˆì„ ì•ˆì •í™”
            stableFrameCountRef.current++;
            const isStableFrame = stableFrameCountRef.current >= STABLE_FRAME_THRESHOLD;

            // ëˆˆê³¼ ì… ëœë“œë§ˆí¬ì—ì„œ EAR, MAR ê³„ì‚°
            let ear = 0.3;
            let mar = 0.0;

            if (face.mesh && face.mesh.length >= 468) {
              // ëˆˆ ëœë“œë§ˆí¬ ì¶”ì¶œ (Humanì˜ face mesh ì‚¬ìš©)
              // MediaPipe Face Mesh ì¸ë±ìŠ¤ì— ë§ëŠ” ì •í™•í•œ ëˆˆ ëœë“œë§ˆí¬
              const leftEyePoints = [
                face.mesh[33],   // ì™¼ìª½ ëˆˆ ì™¸ì¸¡
                face.mesh[160],  // ì™¼ìª½ ëˆˆ ìœ„ìª½
                face.mesh[158],  // ì™¼ìª½ ëˆˆ ìœ„ìª½
                face.mesh[133],  // ì™¼ìª½ ëˆˆ ë‚´ì¸¡
                face.mesh[153],  // ì™¼ìª½ ëˆˆ ì•„ë˜ìª½
                face.mesh[144],  // ì™¼ìª½ ëˆˆ ì•„ë˜ìª½
              ];
              const rightEyePoints = [
                face.mesh[362],  // ì˜¤ë¥¸ìª½ ëˆˆ ì™¸ì¸¡
                face.mesh[385],  // ì˜¤ë¥¸ìª½ ëˆˆ ìœ„ìª½
                face.mesh[387],  // ì˜¤ë¥¸ìª½ ëˆˆ ìœ„ìª½
                face.mesh[263],  // ì˜¤ë¥¸ìª½ ëˆˆ ë‚´ì¸¡
                face.mesh[373],  // ì˜¤ë¥¸ìª½ ëˆˆ ì•„ë˜ìª½
                face.mesh[380],  // ì˜¤ë¥¸ìª½ ëˆˆ ì•„ë˜ìª½
              ];

              const leftEAR = computeEAR(leftEyePoints);
              const rightEAR = computeEAR(rightEyePoints);
              ear = (leftEAR + rightEAR) / 2;

              // ì… ëœë“œë§ˆí¬ ì¶”ì¶œ (ì •í™•í•œ ì… ì˜ì—­ í¬ì¸íŠ¸)
              const mouthPoints = [
                face.mesh[61],   // ì™¼ìª½ ì…ê¼¬ë¦¬
                face.mesh[84],   // ìœ„ìª½ ì…ìˆ  ì¤‘ì•™ ì™¼ìª½
                face.mesh[17],   // ìœ„ìª½ ì…ìˆ  ì¤‘ì•™
                face.mesh[314],  // ìœ„ìª½ ì…ìˆ  ì¤‘ì•™ ì˜¤ë¥¸ìª½
                face.mesh[291],  // ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬
                face.mesh[375],  // ì•„ë˜ìª½ ì…ìˆ  ì¤‘ì•™ ì˜¤ë¥¸ìª½
                face.mesh[321],  // ì•„ë˜ìª½ ì…ìˆ  ì¤‘ì•™
                face.mesh[308],  // ì•„ë˜ìª½ ì…ìˆ  ì¤‘ì•™ ì™¼ìª½
              ];
              mar = computeMAR(mouthPoints);
            }

            const headPose = estimateHeadPose(face);
            const gaze = estimateGazeDirection(face);
            const emotion = face.emotion && face.emotion.length > 0 ? face.emotion[0].emotion : 'neutral';

            // ê¹œë¹¡ì„ ì¹´ìš´íŠ¸ (ì•ˆì •í™” ê¸°ê°„ì—ëŠ” ì •ìƒ ë²”ìœ„ë¡œ ì„¤ì •)
            const rawBlinkRate = detectBlink(ear);
            const blinkRate = isStableFrame ? rawBlinkRate : Math.max(18, rawBlinkRate); // ì•ˆì •í™” ì „ì—ëŠ” ìµœì†Œ 18íšŒ/ë¶„ìœ¼ë¡œ ì„¤ì • (ì •ìƒ ë²”ìœ„)

            // í•˜í’ˆ ê°ì§€
            const isYawning = mar > 0.6; // í•˜í’ˆ ì„ê³„ê°’
            
            // ê³ ê¸‰ ì¡¸ìŒ ê°ì§€ (ì•ˆì •í™”ëœ í”„ë ˆì„ì—ì„œë§Œ ì •í™•í•œ íŒì •)
            const isDrowsy = isStableFrame ? detectAdvancedDrowsiness(ear, mar, headPose, blinkRate) : false;

            // refë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ê°œì„ 
            if (isDrowsy) {
              consecutiveDrowsyFramesRef.current += 1;
              setConsecutiveDrowsyFrames(consecutiveDrowsyFramesRef.current);
            } else {
              consecutiveDrowsyFramesRef.current = 0;
              setConsecutiveDrowsyFrames(0);
            }

            // EAR íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            const newEarHistory = [...earHistoryRef.current, ear].slice(-30);
            earHistoryRef.current = newEarHistory;
            setEarHistory(newEarHistory);

            // ì‹œì„  ì•ˆì •ì„± ê³„ì‚°
            const gazeStability = calculateGazeStability(gaze);
            
            // ì£¼ì˜ì§‘ì¤‘ë„ ê³„ì‚° (ì•ˆì •í™” ê¸°ê°„ì—ëŠ” ë³´ì •ëœ ê°’ ì‚¬ìš©)
            const attentionScore = isStableFrame 
              ? calculateAttentionScore(ear, mar, headPose, gaze, blinkRate, gazeStability)
              : Math.max(70, calculateAttentionScore(ear, mar, headPose, gaze, blinkRate, gazeStability)); // ì•ˆì •í™” ì „ì—ëŠ” ìµœì†Œ 70ì 
            const fatigueLevel = isStableFrame 
              ? assessFatigueLevel(attentionScore, ear, consecutiveDrowsyFramesRef.current)
              : 'low'; // ì´ˆê¸° í”„ë ˆì„ì—ì„œëŠ” í•­ìƒ ë‚®ì€ í”¼ë¡œë„ë¡œ ì„¤ì •
            
            // ì£¼ì˜ì§‘ì¤‘ë„ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            const newAttentionHistory = [...attentionHistoryRef.current, attentionScore].slice(-60);
            attentionHistoryRef.current = newAttentionHistory;
            setAttentionHistory(newAttentionHistory);

            // ê²°ê³¼ ë¡œê¹… (í”„ë ˆì„ 5ê°œë§ˆë‹¤)
            if (frameCountRef.current % 5 === 0) {
              console.log("ğŸ“Š ì–¼êµ´ ë¶„ì„ ê²°ê³¼:", {
                frameCount: stableFrameCountRef.current,
                isStable: isStableFrame,
                ear: ear.toFixed(3),
                mar: mar.toFixed(3),
                blinkRate: isStableFrame ? `${blinkRate}íšŒ/ë¶„ (10ì´ˆ ì¸¡ì •)` : `${blinkRate}íšŒ/ë¶„ (ë³´ì •: ì›ë˜ ${rawBlinkRate})`,
                attentionScore: attentionScore.toFixed(1),
                gazeDirection: gaze,
                headPose: {
                  yaw: headPose.yaw.toFixed(1),
                  pitch: headPose.pitch.toFixed(1),
                  roll: headPose.roll.toFixed(1)
                },
                emotion,
                isDrowsy,
                fatigueLevel,
                confidence: Math.round((face.boxScore || 0.5) * 100)
              });
            }

            const analysisResult = {
              isDrowsy,
              isAttentive: attentionScore > 70,
              emotion,
              ear,
              mar,
              isYawning,
              gazeDirection: gaze,
              headPose,
              blinkRate,
              attentionScore,
              fatigueLevel,
              confidence: Math.round((face.boxScore || 0.5) * 100)
            };

            // ì•ˆì •í™”ëœ ê²½ìš°ì—ë§Œ ê²°ê³¼ ì „ë‹¬
            if (isStableFrame) {
              // console.log("ğŸ”„ onFaceDetected í˜¸ì¶œ ì¤‘... (ì•ˆì •í™” ì™„ë£Œ)", analysisResult);
              onFaceDetected(analysisResult);
            } else {
              console.log("â³ ì•ˆì •í™” ì¤‘... ë¶„ì„ ê²°ê³¼ ëŒ€ê¸°", {
                frameCount: stableFrameCountRef.current,
                threshold: STABLE_FRAME_THRESHOLD,
                remaining: STABLE_FRAME_THRESHOLD - stableFrameCountRef.current
              });
            }
          } else {
            lastDetectionsRef.current = null;
            // ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì‹œ ë” ë¹ ë¥¸ ë°˜ì‘ì„ ìœ„í•´ ì‹œê°„ ë‹¨ì¶•
            const timeSinceLastDetection = Date.now() - lastDetectionTime;
            if (timeSinceLastDetection > 800) {
              console.log(`ğŸ‘¤ ì–¼êµ´ ë¯¸ê°ì§€ ${timeSinceLastDetection}ms ê²½ê³¼ - onFaceNotDetected í˜¸ì¶œ`);
              onFaceNotDetected();
              // ì–¼êµ´ì´ ê°ì§€ë˜ë©´ setLastDetectionTimeì´ ì—…ë°ì´íŠ¸ë¨
            }
          }
        } catch (err) {
          console.error("Human ì–¼êµ´ ë¶„ì„ ì˜¤ë¥˜:", err);
        }
      }
    }, 100); // ê°ì§€ ì£¼ê¸°ë¥¼ 150msì—ì„œ 100msë¡œ ë‹¨ì¶•í•˜ì—¬ ë” ë¹ ë¥¸ ë°˜ì‘
  }, [
    isModelLoaded, 
    showPreview, 
    onFaceDetected, 
    onFaceNotDetected, 
    drawDetections, 
    detectBlink,
    calculateGazeStability,
    detectAdvancedDrowsiness
  ]);

  return {
    isModelLoaded,
    isDetecting,
    isCameraReady,
    startDetection,
    stopDetection: memoizedStopDetection,
    modelLoadingError,
    isStable: stableFrameCountRef.current >= STABLE_FRAME_THRESHOLD
  };
};

